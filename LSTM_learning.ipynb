{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZosWnYZ8yOD"
      },
      "source": [
        "**Changed runtime to GPU and some codes need updates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaZTUPD9JAd_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import spacy\n",
        "import string\n",
        "import re\n",
        "from spacy.symbols import ORTH\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-aNsY7bL9Lu"
      },
      "source": [
        "Import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XijyPU8svsqj"
      },
      "outputs": [],
      "source": [
        "def unpack_dataset():\n",
        "  ! wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz > .None\n",
        "  ! tar -zxf aclImdb_v1.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfCya_ud5WOV"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUYVRaaTMakJ",
        "outputId": "0245e48e-c088-4659-dcd4-dad8c06699ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-18 04:12:27--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  36.1MB/s    in 2.2s    \n",
            "\n",
            "2023-05-18 04:12:29 (36.1 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "unpack_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhwRDvEjMiub",
        "outputId": "83a62964-5eaf-4361-9b0c-64ac3d4a072b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aclImdb  aclImdb_v1.tar.gz  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EekhjW7P-xZ",
        "outputId": "a8fd46ef-3fe3-4951-df65-4f56ba58576e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('aclImdb/imdb.vocab'),\n",
              " PosixPath('aclImdb/train'),\n",
              " PosixPath('aclImdb/test'),\n",
              " PosixPath('aclImdb/README'),\n",
              " PosixPath('aclImdb/imdbEr.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# unpack dataset\n",
        "from pathlib import Path\n",
        "PATH = Path(\"./aclImdb/\")\n",
        "list(PATH.iterdir()) #not mkdir() but iterdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-rg5-ZiRCH0",
        "outputId": "aa4f369e-0415-4ac3-bccb-ce4e1aa19aec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  pos\tunsupBow.feat  urls_pos.txt\n",
            "neg\t\t unsup\turls_neg.txt   urls_unsup.txt\n"
          ]
        }
      ],
      "source": [
        "! ls ./aclImdb/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "Cvu9Ad-YRPyJ",
        "outputId": "d46d68d2-228b-49ac-d0de-8e413a9564ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'when i saw commercials for this i was thinking \"NO WHAT HAS NICK AT NITE DONE!\" because it was taking up \"fresh prince\" slots. well, i still love the fresh prince. but george lopez is a surprisingly good show. i love how not-stereotypical benny is. carmen is a pretty good character, its really funny to see how stupid and overemotional she can be sometimes. i feel bad for the guy who plays max, he looks much younger then he actually is! but max is a fun character, and acted well. and yeah, angie is a little stereotypical, but she has her funny moments. ha ha george does have a big head! nah but he can be really good too. funny show! it definitely should be on more often then home improvement.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "path = PATH/\"train/pos/2449_7.txt\"\n",
        "path.read_text()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48B0LUeNBAvA"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGRoQSkVAc5S"
      },
      "outputs": [],
      "source": [
        "# must clean up the <br space/> from text file\n",
        "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
        "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
        "my_tok = spacy.load('en_core_web_sm')\n",
        "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dedAt8CXtkbp",
        "outputId": "4f629eeb-2aa9-4c35-b24e-a59749a34d55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['when', 'i', 'saw', 'commercials']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# use tokenizer\n",
        "path = PATH/\"train/pos/2449_7.txt\"\n",
        "spacy_tok(path.read_text())[:4]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt-yioxa0zyt"
      },
      "source": [
        "Vocab to index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5gJ5WgO0vEZ",
        "outputId": "9d98ef5f-2c77-41f1-d369-ec246ceda8c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('aclImdb/train/pos/939_10.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "pos_files = list((PATH/\"train\"/\"pos\").iterdir())\n",
        "neg_files = list((PATH/\"train\"/\"neg\").iterdir())\n",
        "all_files = pos_files + neg_files\n",
        "all_files[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQk1tj2lgjYD"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "this code needs an update (5/11/23)\n",
        "i am reading the text file in ascii that are actually not in ascii format\n",
        "'''\n",
        "\n",
        "import codecs\n",
        "counts = Counter()\n",
        "\n",
        "for path in all_files:\n",
        "    # Read the text file using the appropriate encoding\n",
        "    with codecs.open(path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Update the counter with the tokenized text\n",
        "    counts.update(spacy_tok(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDWC4fnRfe_y"
      },
      "source": [
        "removed any words that are less than 5 letters to remove the fillers such as 'the', 'it', 'is'...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAKVx4bMdkES",
        "outputId": "71a95a3b-4448-4168-ba3c-e019eeb7e47a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103163"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(counts.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQYBhTr5e3jD"
      },
      "outputs": [],
      "source": [
        "for word in list(counts):\n",
        "  if counts[word] < 5:\n",
        "    del counts[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQiMqF8dfqyA",
        "outputId": "59bde670-40ca-4f68-c525-6267f37b9d42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33893"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(counts.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7k6bxFefuo1"
      },
      "outputs": [],
      "source": [
        "vocab2index = {\"PAD\": 0, \"UNK\": 1}\n",
        "words = [\"PAD\", \"UNK\"]\n",
        "for word in counts:\n",
        "  vocab2index[word] = len(words)\n",
        "  words.append(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqaDZ4fkOua2"
      },
      "source": [
        "  def decode_sentence_v2(self, path, vocab2index, N):\n",
        "    with codecs.open(path, \"r\", encoding=\"utf-8\") as file:\n",
        "      decoded_sentence = file.read()\n",
        "    \n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFSIAWQNhHFV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import codecs\n",
        "def decode_sentense_v2(path, vocab2index, N= 400):\n",
        "  with codecs.open(path, \"r\", encoding = \"utf-8\") as file:\n",
        "    text = file.read()\n",
        "    x = spacy_tok(text)\n",
        "  if len(x) > N:\n",
        "    start_idx = random.randint(0, len(x) - N)\n",
        "#understand the code here is important. random.randint. not ranint\n",
        "    x = x[start_idx: start_idx + N]\n",
        "  enc = np.zeros(N, dtype = np.int32)\n",
        "  encl = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n",
        "  l = min(N, len(encl))\n",
        "  enc[N-l:] = encl[: l]\n",
        "  return enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah4eEDLPlCia",
        "outputId": "c6bb620f-e866-4115-dfce-e7be55b95da6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           1,   123,   169,   494,   169,   320,     6, 10649,     8,\n",
              "        4320,  1234,   301,    13,   150,   304,  1170,   110,  1609,\n",
              "        1360,   269,  5170,  9522,   269, 13283,     3,  2666,   918,\n",
              "           3, 23441,    36,   153,    63,   905,     6,     1,    97,\n",
              "          47, 25088,  2829,   101,   990,    21,  2306,   525,    68,\n",
              "        2576,    13,   133,    34,  2983,    13,  3245,   217,   453,\n",
              "        1236,   110,   784,    47,    38,  2639,    24,   229,    25,\n",
              "         107,  1832,    36,  2829,    84,     6,   494,  2829,  3894,\n",
              "       19315,    21,   362,   277,  4777,    63,   350,    24,  1170,\n",
              "         399,    36,  1861,    21,    13,  1267,   630,  6918,    36,\n",
              "        3817,    21,    22,   338,   124,    13,  5794,  3203,   133,\n",
              "       15604,    21,   106,   415, 23441,   157, 15490,  7896,    36,\n",
              "          24,    25,  1326,  1583,    84,   248,    21, 30039,    64,\n",
              "          16,   106,   111,     1,   682, 16821,   124,    25,    93,\n",
              "          59,    63,  1912,   160,    21,  1781,   178,   169,   248,\n",
              "         169,  1170,  1058,   242,    47,  3064,   111,  2688,    34,\n",
              "         182,    12,  1935,     6,  3326,   158,  3594,    97,   575,\n",
              "       13107,  5407,    21, 21141,  9146,    21,  1218,   128,   277,\n",
              "        4777,    63,   350,     6, 10649,     8,  3993,  1181,  7199,\n",
              "          36,   875,    21,    17,    13,    92,   214,   125,   124,\n",
              "         612,    47,    38,   133,   355,    74,    13,   673,    93,\n",
              "         390,  9522, 13283,    21,    22,  1081,   103,  2829,    97,\n",
              "          79,  2829,  7227,    36,   182,   103, 25709,   217,  1418,\n",
              "         277, 11447,  1830,   217,   233,  1642,    63,    47,   656,\n",
              "         124,    13,   133,  1827,   269, 21717,   168,    47,   244,\n",
              "        5713,    38,  4933,    21,   301,   838,   104,    47,    38,\n",
              "          36,   162,     1,     6,  4198,  1097,   229,  2829,  2773,\n",
              "         304,   474,     5,     6,  1477,  3924,  4933,  2829,    47,\n",
              "       15490,   158,  1266,     3,     6,  1614,   442, 16161,  1588,\n",
              "          36,    47, 10260, 25088,   313,    21,   132,   162,   784,\n",
              "        9522, 13283,    10,   111,  1124,   229,    21,   675,   122,\n",
              "         162,   277,  1258,   118,   355,   494,  7878,   141,  2829,\n",
              "        1906,   122,    21,  1781, 15897,   857,    24,   183,     6,\n",
              "        7169,  1383,    16,   474,   111,   575,  2193,  1342,     8,\n",
              "       16325,   141,    24,    21], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "path = PATH/\"train/neg/211_4.txt\"\n",
        "decode_sentense_v2(path, vocab2index, N = 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iORXpUCuF2tF"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "fixed the code to change string to ascii format\n",
        "'''\n",
        "class ImdbDataset(Dataset):\n",
        "  def __init__(self, PATH, train = \"train\", N = 400):\n",
        "    self.N = N\n",
        "    self.path_to_images = PATH/train\n",
        "    self.pos_files = list((self.path_to_images/\"pos\").iterdir())\n",
        "    self.neg_files = list((self.path_to_images/\"neg\").iterdir())\n",
        "    self.files = self.pos_files + self.neg_files\n",
        "    self.y = np.concatenate((np.ones(len(self.pos_files), dtype = int), np.zeros(len(self.neg_files), dtype = int)), axis = 0)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    path = self.files[idx]\n",
        "    return decode_sentense_v2(path, vocab2index, self.N), self.y[idx]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJB402IQnnlX"
      },
      "outputs": [],
      "source": [
        "train_ds = ImdbDataset(PATH)\n",
        "test_ds = ImdbDataset(PATH,\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzqBz0szcHU_"
      },
      "outputs": [],
      "source": [
        "batch_size = 1000\n",
        "train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "valid_dl = DataLoader(test_ds, batch_size = batch_size, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2XmPJnkckug"
      },
      "source": [
        "Understanding LSTMs\n",
        "\n",
        "```\n",
        "# Input dim is the dimension of the embedding for each word (2 in the example)\n",
        "# Output dim is the dimension of the hidden layer (4 in this example)\n",
        "# batch_first – If True, then the input and output tensors are provided as (batch, seq, feature).\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqDDsH4XcjN5"
      },
      "outputs": [],
      "source": [
        "lstm = nn.LSTM(2, 4, batch_first = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynY0tODdm8sG"
      },
      "source": [
        "The resulting tensor is then reshaped using the view() function. The view() function creates a new tensor with the same data as the original tensor but with a different shape. In this case, the resulting tensor is reshaped to have dimensions of (1, len(inputs), -1), where 1 is the batch size, len(inputs) is the length of the original list, and -1 is inferred from the size of the input tensors to ensure that the total number of elements in the reshaped tensor is the same as the original tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjYwgsn_mQgp",
        "outputId": "f4774051-1fe7-432f-df0d-5bb1db7e0211"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3676,  0.2871],\n",
              "         [ 0.8069,  0.4595],\n",
              "         [ 0.4303,  1.5000],\n",
              "         [-0.0108, -0.1190],\n",
              "         [ 0.6559,  0.5714]]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "inputs = [torch.randn(1, 2) for _ in range(5)]\n",
        "inputs = torch.cat(inputs).view(1, len(inputs), -1)\n",
        "inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGzeqE_WnGht"
      },
      "source": [
        "```\n",
        "# RNNs assume this input shape\n",
        "# input shape should be  bash_size x seq_len x embedding dimension (if batch_first=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFDMBVPxnIWZ",
        "outputId": "5691023b-bbed-4918-9a7b-b2950a1a4a3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uwnFCYsnLeU"
      },
      "outputs": [],
      "source": [
        "out, hidden = lstm(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcvMIUNysAkX"
      },
      "source": [
        "Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5Wqc4idsCNd"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "    super(LSTMModel, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx = 0)\n",
        "    self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first = True)\n",
        "    self.linearOut = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "#this is forward here\n",
        "  def forward(self,inputs):\n",
        "    x = self.embeddings(inputs)\n",
        "    lstm_out, lstm_h = self.lstm(x)\n",
        "    x = lstm_out[:, -1]\n",
        "    x = self.linearOut(x)\n",
        "    return x, lstm_h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qChBYJQ9hE4Q"
      },
      "outputs": [],
      "source": [
        "def train_epochs(model, train_dl, valid_dl, epochs = 10, lr = 0.001):\n",
        "  parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "  optimizer = torch.optim.Adam(parameters, lr = lr)\n",
        "  for i in range(epochs):\n",
        "    model.train()\n",
        "    sum_loss = 0\n",
        "    total = 0\n",
        "    for x, y in train_dl:\n",
        "      x = x.long().cuda()\n",
        "      y = y.float().cuda()\n",
        "      y_pred, _ = model(x)\n",
        "      optimizer.zero_grad()\n",
        "      loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      sum_loss += loss.item() * y.shape[0]\n",
        "      total += y.shape[0]\n",
        "  print(\"train loss %.3f\" % (sum_loss / total))\n",
        "  test_metrics(model, test_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym9wb9bvrQs5"
      },
      "outputs": [],
      "source": [
        "def test_metrics(model, test_dl):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  sum_loss = 0.0\n",
        "  for x, y in test_dl:\n",
        "    x = x.long().cuda()\n",
        "    y = y.float().cuda().unsqueeze(1)\n",
        "    y_hat, _ = model(x)\n",
        "    loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "    y_pred = y_hat > 0\n",
        "    correct += (y_pred.float() == y).float().sum()\n",
        "    total += y.shape[0]\n",
        "    sum_loss += loss.item() * y.shape[0]\n",
        "  print(\"total loss %.3f and test accuracy %.3f\" % (sum_loss / total, correct / total))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCzREb-WyyAl",
        "outputId": "616c7f3d-30d1-49a5-cdf6-f71d5733cdb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33895\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(words)\n",
        "print(vocab_size)\n",
        "model = LSTMModel(vocab_size, 50, 100).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xHq4VK5-HWX"
      },
      "outputs": [],
      "source": [
        "batch_size = 1000\n",
        "train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "test_dl = DataLoader(test_ds, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A8fz2B6-kwP"
      },
      "outputs": [],
      "source": [
        "train_epochs(model, train_dl, test_dl, epochs = 20, lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVRgyIIlQg8g"
      },
      "outputs": [],
      "source": [
        "def save_model(m, p): torch.save(m.state_dict(), p)\n",
        "def load_model(m, p): m.load_state_dict(torch.load(p))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VPGIyKUqB4f"
      },
      "outputs": [],
      "source": [
        "p = PATH/\"model-1.pth\"\n",
        "save_model(model, p)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
