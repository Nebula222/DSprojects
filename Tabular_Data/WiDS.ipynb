{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WiDS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l-E_i3H84dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable #use to do backpropagation\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "import random\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei1Fek8Tr3Ji",
        "colab_type": "code",
        "outputId": "b7b27d28-7b92-424a-cd52-e08cffb56f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Sgfw98nxPZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = Path('/content/gdrive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm8jarQgykoJ",
        "colab_type": "code",
        "outputId": "40361f80-4715-4cd7-dcd0-6f1ab11911f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "wids = pd.read_csv(PATH/'train.csv')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (12,49,51,56,91,126,145,163,165,166,167,168,169,171,173,174,176,177,242,244,246,248,252,255,274,290,291,292,294,295,296,332,344,366,374,376,397,414,440,491,620,634,639,642,643,645,710,713,760,769,810,829,929,954,979,1001,1002,1003,1004,1005,1024,1037,1041,1043,1062,1086,1099,1100,1121,1129,1136,1152,1153,1166,1168,1182,1193,1204,1205,1207,1208,1216,1226,1228,1230,1232,1234) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMHXHSSC1HwE",
        "colab_type": "code",
        "outputId": "7fcca79d-3025-4b59-b702-989409830c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wids.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18255, 1235)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOmycu3L1P_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in wids.columns:\n",
        "  if wids[col].isnull().sum() > 12000:\n",
        "    wids.drop(col, axis = 1, inplace = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3SXuKeh2EuG",
        "colab_type": "code",
        "outputId": "13e55472-8e40-4cc0-b713-293c4a16e47c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wids.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18255, 422)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lp2XIyC2RDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wids.to_csv(PATH/'train_422.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh94vamK2fMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(PATH/'train_422.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j58tfBeJ22We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = train['is_female'].values.astype(np.float64)\n",
        "X = train.drop(columns= ['is_female'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNX7gp2r3SC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "for col in X.columns:\n",
        "  if X.dtypes[col] == 'object':\n",
        "    X[col] = X[col].fillna('NA')\n",
        "  else:\n",
        "    X[col] = X[col].fillna(0)\n",
        "  le = LabelEncoder()\n",
        "  X[col] = le.fit_transform(X[col])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl8icUCm4YpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in X.columns:\n",
        "  X[col] = X[col].astype('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_HXJWK046RR",
        "colab_type": "code",
        "outputId": "853653b6-8c25-40c8-b014-9b6d48062e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state = 3)\n",
        "X_train.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>train_id</th>\n",
              "      <th>AA3</th>\n",
              "      <th>AA4</th>\n",
              "      <th>AA6</th>\n",
              "      <th>AA7</th>\n",
              "      <th>AA14</th>\n",
              "      <th>AA15</th>\n",
              "      <th>DG1</th>\n",
              "      <th>DG3</th>\n",
              "      <th>DG3A</th>\n",
              "      <th>DG4</th>\n",
              "      <th>DG5_1</th>\n",
              "      <th>DG5_2</th>\n",
              "      <th>DG5_3</th>\n",
              "      <th>DG5_4</th>\n",
              "      <th>DG5_5</th>\n",
              "      <th>DG5_6</th>\n",
              "      <th>DG5_7</th>\n",
              "      <th>DG5_8</th>\n",
              "      <th>DG5_9</th>\n",
              "      <th>DG5_10</th>\n",
              "      <th>DG5_11</th>\n",
              "      <th>DG5_96</th>\n",
              "      <th>DG6</th>\n",
              "      <th>DG8a</th>\n",
              "      <th>DG8b</th>\n",
              "      <th>DG8c</th>\n",
              "      <th>DG9a</th>\n",
              "      <th>DG9b</th>\n",
              "      <th>DG9c</th>\n",
              "      <th>DG10b</th>\n",
              "      <th>DG10c</th>\n",
              "      <th>DG11b</th>\n",
              "      <th>DL0</th>\n",
              "      <th>DL1</th>\n",
              "      <th>DL2</th>\n",
              "      <th>DL3</th>\n",
              "      <th>DL4_1</th>\n",
              "      <th>DL4_2</th>\n",
              "      <th>...</th>\n",
              "      <th>FB26_4</th>\n",
              "      <th>FB26_5</th>\n",
              "      <th>FB26_6</th>\n",
              "      <th>FB26_7</th>\n",
              "      <th>FB26_8</th>\n",
              "      <th>FB26_9</th>\n",
              "      <th>FB26_10</th>\n",
              "      <th>FB26_11</th>\n",
              "      <th>FB26_96</th>\n",
              "      <th>FB26_99</th>\n",
              "      <th>FB27_1</th>\n",
              "      <th>FB27_2</th>\n",
              "      <th>FB27_3</th>\n",
              "      <th>FB27_4</th>\n",
              "      <th>FB27_5</th>\n",
              "      <th>FB27_6</th>\n",
              "      <th>FB27_7</th>\n",
              "      <th>FB27_8</th>\n",
              "      <th>FB27_9</th>\n",
              "      <th>FB27_96</th>\n",
              "      <th>FB29_1</th>\n",
              "      <th>FB29_2</th>\n",
              "      <th>FB29_3</th>\n",
              "      <th>FB29_4</th>\n",
              "      <th>FB29_5</th>\n",
              "      <th>FB29_6</th>\n",
              "      <th>FB29_96</th>\n",
              "      <th>LN1A</th>\n",
              "      <th>LN1B</th>\n",
              "      <th>LN2_1</th>\n",
              "      <th>LN2_2</th>\n",
              "      <th>LN2_3</th>\n",
              "      <th>LN2_4</th>\n",
              "      <th>LN2_RIndLngBEOth</th>\n",
              "      <th>LN2_WIndLngBEOth</th>\n",
              "      <th>GN1</th>\n",
              "      <th>GN2</th>\n",
              "      <th>GN3</th>\n",
              "      <th>GN4</th>\n",
              "      <th>GN5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11369</th>\n",
              "      <td>11369</td>\n",
              "      <td>11369</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>424</td>\n",
              "      <td>482</td>\n",
              "      <td>252</td>\n",
              "      <td>62</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1250</th>\n",
              "      <td>1250</td>\n",
              "      <td>1250</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>831</td>\n",
              "      <td>831</td>\n",
              "      <td>410</td>\n",
              "      <td>63</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7527</th>\n",
              "      <td>7527</td>\n",
              "      <td>7527</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>301</td>\n",
              "      <td>310</td>\n",
              "      <td>166</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13476</th>\n",
              "      <td>13476</td>\n",
              "      <td>13476</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>664</td>\n",
              "      <td>564</td>\n",
              "      <td>300</td>\n",
              "      <td>69</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13406</th>\n",
              "      <td>13406</td>\n",
              "      <td>13406</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>587</td>\n",
              "      <td>111</td>\n",
              "      <td>76</td>\n",
              "      <td>58</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 422 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0 train_id AA3 AA4 AA6  AA7  ... LN2_WIndLngBEOth GN1 GN2 GN3 GN4 GN5\n",
              "11369      11369    11369   1  10   2  424  ...               38   0   1   1   1   1\n",
              "1250        1250     1250   2  17   1  831  ...               32   1   2   2   0   0\n",
              "7527        7527     7527   1   8   0  301  ...               38   2   1   1   1   1\n",
              "13476      13476    13476   2  14   2  664  ...               14   3   2   2   2   2\n",
              "13406      13406    13406   0  12   3  587  ...               14   1   0   2   2   2\n",
              "\n",
              "[5 rows x 422 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HqhECcv5PFA",
        "colab_type": "code",
        "outputId": "7087ce57-16bf-422c-84a4-e534c37e1ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "emb_c = {n: len(col.cat.categories) for n, col in X.items() if len(col.cat.categories) > 2}\n",
        "emb_c"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AA14': 907,\n",
              " 'AA15': 450,\n",
              " 'AA3': 4,\n",
              " 'AA4': 22,\n",
              " 'AA6': 4,\n",
              " 'AA7': 1050,\n",
              " 'DG1': 79,\n",
              " 'DG10b': 9,\n",
              " 'DG10c': 8,\n",
              " 'DG11b': 9,\n",
              " 'DG3': 9,\n",
              " 'DG3A': 8,\n",
              " 'DG4': 12,\n",
              " 'DG6': 9,\n",
              " 'DG8a': 13,\n",
              " 'DG8b': 13,\n",
              " 'DG8c': 13,\n",
              " 'DG9a': 12,\n",
              " 'DG9b': 11,\n",
              " 'DG9c': 8,\n",
              " 'DL1': 12,\n",
              " 'DL11': 15,\n",
              " 'DL14': 24,\n",
              " 'DL15': 4,\n",
              " 'DL2': 33,\n",
              " 'DL24': 7,\n",
              " 'DL3': 3,\n",
              " 'DL5': 25,\n",
              " 'DL7': 3,\n",
              " 'DL8': 342,\n",
              " 'FB13': 25,\n",
              " 'FB18': 5,\n",
              " 'FB19': 11,\n",
              " 'FB19B_1': 4,\n",
              " 'FB19B_2': 4,\n",
              " 'FB19B_3': 4,\n",
              " 'FB19B_4': 4,\n",
              " 'FB19B_5': 4,\n",
              " 'FB19B_96': 4,\n",
              " 'FB2': 3,\n",
              " 'FB20': 16,\n",
              " 'FB24': 17,\n",
              " 'FB26_1': 3,\n",
              " 'FB26_10': 3,\n",
              " 'FB26_11': 3,\n",
              " 'FB26_2': 3,\n",
              " 'FB26_3': 3,\n",
              " 'FB26_4': 3,\n",
              " 'FB26_5': 3,\n",
              " 'FB26_6': 3,\n",
              " 'FB26_7': 3,\n",
              " 'FB26_8': 3,\n",
              " 'FB26_9': 3,\n",
              " 'FB26_96': 3,\n",
              " 'FB26_99': 3,\n",
              " 'FF10_1': 3,\n",
              " 'FF10_2': 3,\n",
              " 'FF10_3': 3,\n",
              " 'FF10_4': 3,\n",
              " 'FF10_5': 3,\n",
              " 'FF10_6': 3,\n",
              " 'FF10_96': 3,\n",
              " 'FF13': 8,\n",
              " 'FF14_1': 3,\n",
              " 'FF14_10': 3,\n",
              " 'FF14_11': 3,\n",
              " 'FF14_12': 3,\n",
              " 'FF14_13': 3,\n",
              " 'FF14_14': 3,\n",
              " 'FF14_15': 3,\n",
              " 'FF14_16': 3,\n",
              " 'FF14_17': 3,\n",
              " 'FF14_18': 3,\n",
              " 'FF14_19': 3,\n",
              " 'FF14_2': 3,\n",
              " 'FF14_20': 3,\n",
              " 'FF14_21': 3,\n",
              " 'FF14_22': 3,\n",
              " 'FF14_23': 3,\n",
              " 'FF14_3': 3,\n",
              " 'FF14_4': 3,\n",
              " 'FF14_5': 3,\n",
              " 'FF14_6': 3,\n",
              " 'FF14_7': 3,\n",
              " 'FF14_8': 3,\n",
              " 'FF14_9': 3,\n",
              " 'FF14_96': 3,\n",
              " 'FF16_1': 6,\n",
              " 'FF16_2': 6,\n",
              " 'FF19_1': 3,\n",
              " 'FF19_2': 3,\n",
              " 'FF19_3': 3,\n",
              " 'FF19_4': 3,\n",
              " 'FF19_5': 3,\n",
              " 'FF19_6': 3,\n",
              " 'FF19_7': 3,\n",
              " 'FF19_8': 3,\n",
              " 'FF2': 4,\n",
              " 'FF2A': 18,\n",
              " 'FF3': 27,\n",
              " 'FF4': 3,\n",
              " 'FF5': 4,\n",
              " 'FF6_1': 4,\n",
              " 'FF6_10': 4,\n",
              " 'FF6_2': 4,\n",
              " 'FF6_3': 4,\n",
              " 'FF6_4': 4,\n",
              " 'FF6_5': 4,\n",
              " 'FF6_6': 4,\n",
              " 'FF6_7': 4,\n",
              " 'FF6_8': 4,\n",
              " 'FF6_9': 4,\n",
              " 'FF7_1': 4,\n",
              " 'FF7_2': 4,\n",
              " 'FF7_4': 5,\n",
              " 'FF7_5': 4,\n",
              " 'FF7_6': 3,\n",
              " 'FF9': 7,\n",
              " 'FL1': 4,\n",
              " 'FL10': 13,\n",
              " 'FL11': 5,\n",
              " 'FL12': 3,\n",
              " 'FL14': 3,\n",
              " 'FL15': 4,\n",
              " 'FL16': 3,\n",
              " 'FL17': 3,\n",
              " 'FL18': 3,\n",
              " 'FL2': 5,\n",
              " 'FL3': 10,\n",
              " 'FL4': 19,\n",
              " 'FL7_1': 3,\n",
              " 'FL7_2': 3,\n",
              " 'FL7_3': 3,\n",
              " 'FL7_4': 3,\n",
              " 'FL7_5': 3,\n",
              " 'FL7_6': 3,\n",
              " 'FL8_1': 5,\n",
              " 'FL8_2': 5,\n",
              " 'FL8_3': 5,\n",
              " 'FL8_4': 5,\n",
              " 'FL8_5': 5,\n",
              " 'FL8_6': 5,\n",
              " 'FL8_7': 5,\n",
              " 'FL9A': 12,\n",
              " 'FL9B': 13,\n",
              " 'FL9C': 13,\n",
              " 'GN1': 7,\n",
              " 'GN2': 6,\n",
              " 'GN3': 6,\n",
              " 'GN4': 6,\n",
              " 'GN5': 6,\n",
              " 'IFI14_1': 7,\n",
              " 'IFI14_2': 7,\n",
              " 'IFI14_3': 7,\n",
              " 'IFI14_4': 7,\n",
              " 'IFI14_5': 7,\n",
              " 'IFI14_6': 7,\n",
              " 'IFI14_7': 7,\n",
              " 'IFI15_1': 7,\n",
              " 'IFI15_2': 7,\n",
              " 'IFI15_3': 7,\n",
              " 'IFI15_4': 7,\n",
              " 'IFI15_5': 7,\n",
              " 'IFI15_6': 7,\n",
              " 'IFI15_7': 7,\n",
              " 'IFI16_1': 11,\n",
              " 'IFI16_2': 11,\n",
              " 'IFI17_1': 7,\n",
              " 'IFI17_2': 7,\n",
              " 'IFI18': 9,\n",
              " 'IFI24': 12,\n",
              " 'LN1A': 4,\n",
              " 'LN1B': 4,\n",
              " 'LN2_1': 5,\n",
              " 'LN2_2': 5,\n",
              " 'LN2_3': 5,\n",
              " 'LN2_4': 5,\n",
              " 'LN2_RIndLngBEOth': 58,\n",
              " 'LN2_WIndLngBEOth': 59,\n",
              " 'MM3_1': 3,\n",
              " 'MM3_10': 3,\n",
              " 'MM3_11': 3,\n",
              " 'MM3_12': 3,\n",
              " 'MM3_13': 3,\n",
              " 'MM3_14': 3,\n",
              " 'MM3_2': 3,\n",
              " 'MM3_3': 3,\n",
              " 'MM3_4': 3,\n",
              " 'MM3_5': 3,\n",
              " 'MM3_6': 3,\n",
              " 'MM3_7': 3,\n",
              " 'MM3_8': 3,\n",
              " 'MM3_9': 3,\n",
              " 'MT1': 13,\n",
              " 'MT11': 83,\n",
              " 'MT12_1': 5,\n",
              " 'MT12_11': 5,\n",
              " 'MT12_12': 3,\n",
              " 'MT12_13': 3,\n",
              " 'MT12_14': 3,\n",
              " 'MT12_2': 7,\n",
              " 'MT12_3': 6,\n",
              " 'MT12_4': 3,\n",
              " 'MT12_5': 3,\n",
              " 'MT12_7': 5,\n",
              " 'MT12_9': 3,\n",
              " 'MT14C_1': 5,\n",
              " 'MT14C_2': 5,\n",
              " 'MT14C_3': 5,\n",
              " 'MT14C_4': 5,\n",
              " 'MT15': 3,\n",
              " 'MT17_1': 7,\n",
              " 'MT17_10': 7,\n",
              " 'MT17_11': 7,\n",
              " 'MT17_12': 7,\n",
              " 'MT17_13': 7,\n",
              " 'MT17_2': 7,\n",
              " 'MT17_3': 7,\n",
              " 'MT17_4': 7,\n",
              " 'MT17_5': 7,\n",
              " 'MT17_6': 7,\n",
              " 'MT17_7': 7,\n",
              " 'MT17_8': 7,\n",
              " 'MT17_9': 7,\n",
              " 'MT18_1': 3,\n",
              " 'MT18_2': 3,\n",
              " 'MT18_3': 3,\n",
              " 'MT18_4': 3,\n",
              " 'MT18_5': 3,\n",
              " 'MT18_6': 3,\n",
              " 'MT18_8': 3,\n",
              " 'MT18_96': 3,\n",
              " 'MT1A': 8,\n",
              " 'MT3_1': 5,\n",
              " 'MT3_2': 6,\n",
              " 'MT3_3': 6,\n",
              " 'MT4_1': 3,\n",
              " 'MT4_2': 3,\n",
              " 'MT4_3': 3,\n",
              " 'MT4_4': 3,\n",
              " 'MT4_5': 3,\n",
              " 'MT4_6': 3,\n",
              " 'MT5': 8,\n",
              " 'MT6': 10,\n",
              " 'MT6A': 7,\n",
              " 'MT6B': 9,\n",
              " 'MT6C': 28,\n",
              " 'MT7': 3,\n",
              " 'Unnamed: 0': 18255,\n",
              " 'train_id': 18255}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCIfTep96UAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_szs = [(c, min(50, (c + 1) // 2)) for _,c in emb_c.items()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gfh9LXH6sRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_cols = emb_c.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYNIOs7E65cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class widsDataset(Dataset):\n",
        "  def __init__(self, X, Y, emb_cols):\n",
        "    X = X.copy()\n",
        "    self.X1 = X.loc[:, emb_cols].copy().values.astype(np.int64)\n",
        "    self.X2 = X.drop(columns = emb_cols).copy().values.astype(np.float32)\n",
        "    self.y = Y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return [self.X1[idx], self.X2[idx], self.y[idx]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6YKs366Hwkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = widsDataset(X_train, Y_train, emb_cols)\n",
        "valid_ds = widsDataset(X_val, Y_val, emb_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhO6iuNwIPYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGPwYPYYI2P6",
        "colab_type": "text"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFkHUnvKIuCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MixedInputModel(nn.Module):\n",
        "  def __init__(self, emb_szs, n_cont):\n",
        "    super().__init__()\n",
        "    self.embs = nn.ModuleList([nn.Embedding(c, s) for c, s in emb_szs])\n",
        "    n_emb = sum(e.embedding_dim for e in self.embs)\n",
        "    self.n_emb, self.n_cont = n_emb, n_cont\n",
        "    self.lin1 = nn.Linear(self.n_emb + self.n_cont, 100)\n",
        "    self.lin2 = nn.Linear(100, 1)\n",
        "    self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
        "    self.bn2 = nn.BatchNorm1d(100)\n",
        "    self.emb_drop = nn.Dropout(0.5)\n",
        "    self.drops = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x_cat, x_cont):\n",
        "    x = [e(x_cat[:,i]) for i, e in enumerate(self.embs)]\n",
        "    x = torch.cat(x, 1)\n",
        "    x = self.emb_drop(x)\n",
        "    x2 = self.bn1(x_cont)\n",
        "    x = torch.cat([x, x2], 1)\n",
        "    x = F.relu(self.lin1(x))\n",
        "    x = self.drops(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.lin2(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJbCapPckU3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MixedInputModel(emb_szs, 172)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dievPK4Rr_to",
        "colab_type": "code",
        "outputId": "66f2237d-0760-4da7-9465-763f48bb3840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x1, x2, y = next(iter(train_dl))\n",
        "print(x1.shape, x2.shape, y.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 250]) torch.Size([5, 172]) torch.Size([5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2-DrsaWsRoF",
        "colab_type": "code",
        "outputId": "67464fd4-9955-48a6-821d-d987191aea0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y = y.unsqueeze(1)\n",
        "out = model(x1, x2)\n",
        "out"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1707],\n",
              "        [-0.1786],\n",
              "        [-0.1172],\n",
              "        [ 0.0375],\n",
              "        [ 0.5010]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqbLRmnH7nfJ",
        "colab_type": "code",
        "outputId": "d2dbccd1-192e-4380-e1bc-d20761538ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZQjIM657pxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = (out > 0.0).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbSurh-B7uT9",
        "colab_type": "code",
        "outputId": "6b8f9ea4-1260-4aad-8855-5898fce0e418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(pred == y).float().sum()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_W0wK2l7zPC",
        "colab_type": "code",
        "outputId": "07e6597f-2222-4d0d-88cd-3c391ab1b9d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "F.binary_cross_entropy_with_logits(out, y)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7367, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcDKEYb28G-O",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l97mbXgt767B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
        "  parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "  optim = torch.optim.Adam(parameters, lr = lr, weight_decay= wd)\n",
        "  return optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYnh1Hmi9hug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, optim, train_dl = train_dl, verbose = False):\n",
        "  model.train()\n",
        "  total = 0\n",
        "  sum_loss = 0\n",
        "  for i, (x1, x2, y) in enumerate(train_dl):\n",
        "    batch = y.shape[0]\n",
        "    y = y.unsqueeze(1)\n",
        "    out = model(x1, x2)\n",
        "    loss = F.binary_cross_entropy_with_logits(out, y)\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    total += batch\n",
        "    sum_loss += batch * (loss.item())\n",
        "    if verbose: print(sum_loss/total)\n",
        "  return sum_loss/total\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JujtfezhKuCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_loss(model, valid_dl):\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  sum_loss = 0\n",
        "  correct = 0\n",
        "  for i, (x1, x2, y) in enumerate(valid_dl):\n",
        "    batch = y.shape[0]\n",
        "    y = y.unsqueeze(1)\n",
        "    out = model(x1, x2)\n",
        "    loss = F.binary_cross_entropy_with_logits(out, y)\n",
        "    sum_loss += batch* (loss.item())\n",
        "    total += batch\n",
        "    pred = (out > 0).float()\n",
        "    correct += (pred == y).float().sum().item()\n",
        "  print(\"val_loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n",
        "  return sum_loss/total, correct/total\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS6HN2VzMj-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def train_loop(model, epochs, lr = 0.1, wd = 0.0):\n",
        "  optim = get_optimizer(model, lr = lr, wd = wd)\n",
        "  for i in range(epochs):\n",
        "    loss = train_model(model, optim, train_dl)\n",
        "    print(\"loss = \", loss)\n",
        "    val_loss(model, valid_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UodVTLZGN5f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 500\n",
        "train_dl = DataLoader(train_ds, batch_size = batch_size)\n",
        "valid_dl = DataLoader(valid_ds, batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw5cLT5TOKQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MixedInputModel(emb_szs, 172)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of6tBRCEOkIe",
        "colab_type": "code",
        "outputId": "474b5268-9700-40a8-cb12-5d29e1cfb276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "train_loop(model, epochs = 10, lr = 0.05, wd = 0.00001)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss =  0.4399178168506565\n",
            "val_loss 0.304 and accuracy 0.875\n",
            "loss =  0.28318098602115993\n",
            "val_loss 0.250 and accuracy 0.891\n",
            "loss =  0.23981749311485412\n",
            "val_loss 0.242 and accuracy 0.900\n",
            "loss =  0.19719872880197492\n",
            "val_loss 0.270 and accuracy 0.895\n",
            "loss =  0.07611803467413786\n",
            "val_loss 0.349 and accuracy 0.902\n",
            "loss =  0.07789517251682328\n",
            "val_loss 0.310 and accuracy 0.887\n",
            "loss =  0.07244532254032976\n",
            "val_loss 0.344 and accuracy 0.876\n",
            "loss =  0.03200919267863558\n",
            "val_loss 0.445 and accuracy 0.871\n",
            "loss =  0.026930038575659513\n",
            "val_loss 0.385 and accuracy 0.890\n",
            "loss =  0.032678859803740926\n",
            "val_loss 0.412 and accuracy 0.892\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}