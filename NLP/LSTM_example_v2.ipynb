{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_v3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECg-QGvlUwj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import spacy\n",
        "import string\n",
        "import re\n",
        "from spacy.symbols import ORTH #ID for each word\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn #import modules and parameters and convolution layers\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMBvBsmkcZdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_dataset():\n",
        "  ! wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz > .None\n",
        "  ! tar -xzf aclImdb_v1.tar.gz > .None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vq_ReMNdRTP",
        "colab_type": "code",
        "outputId": "86da47cb-3bd4-4a07-d800-c9039779085a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "download_dataset()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-28 19:09:06--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  19.7MB/s    in 6.4s    \n",
            "\n",
            "2020-04-28 19:09:13 (12.6 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z8x_k7vdcya",
        "colab_type": "code",
        "outputId": "aa96fd38-f278-4104-d731-d3d4f1b64078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb  aclImdb_v1.tar.gz  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgv47u1ifQE7",
        "colab_type": "code",
        "outputId": "012760fc-9c05-4b19-eea7-ede4eb710e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!./aclImdb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ./aclImdb: Is a directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7w2D7vqfkBB",
        "colab_type": "code",
        "outputId": "65a9a1ac-4102-4309-861d-f66c7c5ad763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from pathlib import Path\n",
        "PATH = Path('./aclImdb')\n",
        "list(PATH.iterdir())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('aclImdb/test'),\n",
              " PosixPath('aclImdb/README'),\n",
              " PosixPath('aclImdb/train'),\n",
              " PosixPath('aclImdb/imdbEr.txt'),\n",
              " PosixPath('aclImdb/imdb.vocab')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBm1GJLkgpr8",
        "colab_type": "code",
        "outputId": "eff686d9-615c-4597-ae2f-3d58f4c1f640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "path = PATH/'train/neg/211_4.txt'\n",
        "path.read_text()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hilariously obvious \"drama\" about a bunch of high school (I think) kids who enjoy non-stop hip-hop, break dancing, graffiti and trying to become a dj at the Roxy--or something. To be totally honest I was so bored I forgot! Even people who love the music agree this movie is terribly acted and--as a drama--failed dismally. We\\'re supposed to find this kids likable and nice. I found them bland and boring. The one that I REALLY hated was Ramon. He does graffiti on subway trains and this is looked upon as great. Excuse me? He\\'s defacing public property that isn\\'t his to begin with. Also these \"great\" kids tap into the city\\'s electricity so they can hold a big dance party at an abandoned building. Uh huh. So we\\'re supposed to find a bunch of law breakers lovable and fun.<br /><br />I could forgive all that if the music was good but I can\\'t stand hip hop. The songs were--at best--mediocre and they were nonstop! They\\'re ALWAYS playing! It got to the point that I was fast-forwarding through the many endless music numbers. (Cut out the music and you haver a 30 minute movie--maybe) There are a few imaginative numbers--the subway dance fight, a truly funny Santa number and the climatic Roxy show. If you love hip hop here\\'s your movie. But it you\\'re looking for good drama mixed in--forget it. Also HOW did this get a PG rating? There\\'s an incredible amount of swearing in this.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG0zw7QWM7gM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE) #ignore ', <, \\', ?\n",
        "def sub_br(x): return re_br.sub(\"\\n\", x.lower()) #replace a string using regular expression instead of a perfect match, then use .sub()\n",
        "\n",
        "my_tok = spacy.load('en')\n",
        "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS0SlMhTO8UH",
        "colab_type": "code",
        "outputId": "1fff6483-9773-4bd3-a475-faf61b072185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "path = PATH/'train/neg/211_4.txt'\n",
        "spacy_tok(path.read_text())[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hilariously',\n",
              " 'obvious',\n",
              " '\"',\n",
              " 'drama',\n",
              " '\"',\n",
              " 'about',\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'high']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZHspYZ9PPA0",
        "colab_type": "code",
        "outputId": "8f362424-4422-4d83-c34f-05aa9c93dfd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "pos_files = list((PATH/\"train\"/\"pos\").iterdir())\n",
        "neg_files = list((PATH/\"train\"/\"neg\").iterdir())\n",
        "all_files = pos_files + neg_files\n",
        "all_files[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('aclImdb/train/pos/9667_9.txt'),\n",
              " PosixPath('aclImdb/train/pos/10342_7.txt'),\n",
              " PosixPath('aclImdb/train/pos/7144_10.txt'),\n",
              " PosixPath('aclImdb/train/pos/5424_10.txt'),\n",
              " PosixPath('aclImdb/train/pos/3615_9.txt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UgcqJ_AQb81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counts = Counter() #dict subclass for counting hash objects\n",
        "for path in all_files:\n",
        "  counts.update(spacy_tok(path.read_text())) #like dict.update(), add counts instead of replacing them"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzfOimYHQxFm",
        "colab_type": "code",
        "outputId": "60bc0e8d-0654-4700-da97-9ce93fa925f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(counts.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87048"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1M1kr-cRghI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word in list(counts):\n",
        "  if counts[word] < 5:\n",
        "    del counts[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oDp4kjySnZk",
        "colab_type": "code",
        "outputId": "b5bf0953-2be6-47ff-f7a2-a93ba1202b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(counts.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29364"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ0No0UhSti0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab2index = {\"\":0, \"UNK\":1}\n",
        "words = [\"\", \"UNK\"]\n",
        "for word in counts:\n",
        "  vocab2index[word] = len(words)\n",
        "  words.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQgaSG7Vsn-m",
        "colab_type": "code",
        "outputId": "da0d9dff-820d-4ac1-a406-d38a9e34f45e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vocab2index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " 'UNK': 1,\n",
              " 'story': 2,\n",
              " 'of': 3,\n",
              " 'ireland': 4,\n",
              " 'in': 5,\n",
              " 'the': 6,\n",
              " '70': 7,\n",
              " '/': 8,\n",
              " 's': 9,\n",
              " '.': 10,\n",
              " 'this': 11,\n",
              " 'film': 12,\n",
              " 'is': 13,\n",
              " 'a': 14,\n",
              " 'beautiful': 15,\n",
              " 'reconstruction': 16,\n",
              " 'small': 17,\n",
              " 'time': 18,\n",
              " '1970': 19,\n",
              " 'all': 20,\n",
              " 'gang': 21,\n",
              " 'are': 22,\n",
              " 'there': 23,\n",
              " 'see': 24,\n",
              " 'below': 25,\n",
              " 'master': 26,\n",
              " 'boyle': 27,\n",
              " ',': 28,\n",
              " 'boys': 29,\n",
              " 'cannon': 30,\n",
              " 'sp': 31,\n",
              " \"o'donnell\": 32,\n",
              " 'senator': 33,\n",
              " \"'s\": 34,\n",
              " 'rose': 35,\n",
              " 'agnes': 36,\n",
              " 'and': 37,\n",
              " 'una': 38,\n",
              " 'as': 39,\n",
              " 'it': 40,\n",
              " 'was': 41,\n",
              " '\\n\\n': 42,\n",
              " 'melvyn': 43,\n",
              " 'douglas': 44,\n",
              " 'once': 45,\n",
              " 'more': 46,\n",
              " 'gives': 47,\n",
              " 'polished': 48,\n",
              " 'performance': 49,\n",
              " 'which': 50,\n",
              " 'he': 51,\n",
              " 'inhabits': 52,\n",
              " 'role': 53,\n",
              " 'detective': 54,\n",
              " 'who': 55,\n",
              " 'ca': 56,\n",
              " \"n't\": 57,\n",
              " 'place': 58,\n",
              " 'love': 59,\n",
              " 'before': 60,\n",
              " 'duty': 61,\n",
              " 'adventure': 62,\n",
              " 'warmly': 63,\n",
              " 'joan': 64,\n",
              " 'blondell': 65,\n",
              " '(': 66,\n",
              " 'far': 67,\n",
              " 'from': 68,\n",
              " 'being': 69,\n",
              " 'illiterate': 70,\n",
              " 'one': 71,\n",
              " 'reviewer': 72,\n",
              " 'suggested': 73,\n",
              " 'wrote': 74,\n",
              " 'novel': 75,\n",
              " 'about': 76,\n",
              " 'her': 77,\n",
              " 'early': 78,\n",
              " 'life': 79,\n",
              " ')': 80,\n",
              " 'enjoyable': 81,\n",
              " 'ever': 82,\n",
              " 'his': 83,\n",
              " '-': 84,\n",
              " 'suffering': 85,\n",
              " 'almost': 86,\n",
              " 'screwball': 87,\n",
              " 'comedy': 88,\n",
              " 'thin': 89,\n",
              " 'man': 90,\n",
              " 'type': 91,\n",
              " 'movie': 92,\n",
              " 'series': 93,\n",
              " 'i': 94,\n",
              " 'guess': 95,\n",
              " 'that': 96,\n",
              " 'did': 97,\n",
              " 'quite': 98,\n",
              " 'make': 99,\n",
              " 'to': 100,\n",
              " 'sequel': 101,\n",
              " 'does': 102,\n",
              " 'reach': 103,\n",
              " 'classic': 104,\n",
              " 'status': 105,\n",
              " 'but': 106,\n",
              " 'has': 107,\n",
              " 'ingredients': 108,\n",
              " 'for': 109,\n",
              " 'fun': 110,\n",
              " '85': 111,\n",
              " 'minutes': 112,\n",
              " 'with': 113,\n",
              " 'an': 114,\n",
              " 'episodic': 115,\n",
              " 'script': 116,\n",
              " 'fine': 117,\n",
              " 'character': 118,\n",
              " 'actors': 119,\n",
              " 'direction': 120,\n",
              " 'keeps': 121,\n",
              " 'moving': 122,\n",
              " 'fast': 123,\n",
              " 'enough': 124,\n",
              " 'so': 125,\n",
              " 'you': 126,\n",
              " 'nearly': 127,\n",
              " 'do': 128,\n",
              " 'notice': 129,\n",
              " 'williams': 130,\n",
              " 'exactly': 131,\n",
              " 'columbo': 132,\n",
              " 'when': 133,\n",
              " 'comes': 134,\n",
              " 'wish': 135,\n",
              " 'were': 136,\n",
              " 'films': 137,\n",
              " 'like': 138,\n",
              " 'have': 139,\n",
              " 'seen': 140,\n",
              " 'holes': 141,\n",
              " 'say': 142,\n",
              " 'be': 143,\n",
              " 'best': 144,\n",
              " 'year': 145,\n",
              " 'long': 146,\n",
              " 'brings': 147,\n",
              " 'out': 148,\n",
              " 'child': 149,\n",
              " 'everyone': 150,\n",
              " 'mean': 151,\n",
              " 'would': 152,\n",
              " 'come': 153,\n",
              " 'up': 154,\n",
              " 'idea': 155,\n",
              " 'having': 156,\n",
              " 'troublesome': 157,\n",
              " 'dig': 158,\n",
              " 'their': 159,\n",
              " 'punishment': 160,\n",
              " '?': 161,\n",
              " 'louis': 162,\n",
              " 'sachar': 163,\n",
              " 'although': 164,\n",
              " 'different': 165,\n",
              " 'book': 166,\n",
              " 'still': 167,\n",
              " 'very': 168,\n",
              " 'good': 169,\n",
              " 'example': 170,\n",
              " 'caveman': 171,\n",
              " 'stanley': 172,\n",
              " 'supposed': 173,\n",
              " 'biggest': 174,\n",
              " 'weight': 175,\n",
              " 'wise': 176,\n",
              " 'height': 177,\n",
              " 'ricky': 178,\n",
              " 'taller': 179,\n",
              " 'armpit': 180,\n",
              " 'theodore': 181,\n",
              " 'bigger': 182,\n",
              " 'also': 183,\n",
              " 'x': 184,\n",
              " 'ray': 185,\n",
              " 'rex': 186,\n",
              " 'smallest': 187,\n",
              " 'only': 188,\n",
              " 'thing': 189,\n",
              " 'flashbacks': 190,\n",
              " 'rather': 191,\n",
              " 'persuasive': 192,\n",
              " 'present': 193,\n",
              " 'than': 194,\n",
              " 'past': 195,\n",
              " 'just': 196,\n",
              " 'my': 197,\n",
              " 'opinion': 198,\n",
              " 'especially': 199,\n",
              " 'work': 200,\n",
              " 'though': 201,\n",
              " 'squid': 202,\n",
              " 'alan': 203,\n",
              " 'played': 204,\n",
              " 'by': 205,\n",
              " 'jake': 206,\n",
              " 'moody': 207,\n",
              " 'tough': 208,\n",
              " 'kid': 209,\n",
              " 'performed': 210,\n",
              " 'great': 211,\n",
              " 'job': 212,\n",
              " 'at': 213,\n",
              " 'if': 214,\n",
              " 'nt': 215,\n",
              " 'yet': 216,\n",
              " 'then': 217,\n",
              " 'should': 218,\n",
              " 'again': 219,\n",
              " 'or': 220,\n",
              " \"'ll\": 221,\n",
              " 'missing': 222,\n",
              " 'on': 223,\n",
              " 'whole': 224,\n",
              " 'lotta': 225,\n",
              " '\"': 226,\n",
              " 'gunga': 227,\n",
              " 'din': 228,\n",
              " ':': 229,\n",
              " 'greatest': 230,\n",
              " 'stories': 231,\n",
              " 'told': 232,\n",
              " '!': 233,\n",
              " 'british': 234,\n",
              " 'foreign': 235,\n",
              " 'legion': 236,\n",
              " '19th': 237,\n",
              " 'century': 238,\n",
              " 'india': 239,\n",
              " 'lowly': 240,\n",
              " 'water': 241,\n",
              " 'bearer': 242,\n",
              " 'named': 243,\n",
              " 'local': 244,\n",
              " 'aspires': 245,\n",
              " 'military': 246,\n",
              " 'counterparts': 247,\n",
              " ';': 248,\n",
              " 'three': 249,\n",
              " 'sergeants': 250,\n",
              " 'whose': 251,\n",
              " 'loyalty': 252,\n",
              " 'camaraderie': 253,\n",
              " 'each': 254,\n",
              " 'other': 255,\n",
              " 'extend': 256,\n",
              " 'beyond': 257,\n",
              " 'bounds': 258,\n",
              " 'mere': 259,\n",
              " 'patriotism': 260,\n",
              " 'true': 261,\n",
              " 'abiding': 262,\n",
              " 'friendship': 263,\n",
              " 'another': 264,\n",
              " 'willing': 265,\n",
              " 'sacrifice': 266,\n",
              " 'own': 267,\n",
              " 'longs': 268,\n",
              " 'soldier': 269,\n",
              " 'too': 270,\n",
              " 'particular': 271,\n",
              " 'can': 272,\n",
              " 'never': 273,\n",
              " 'attain': 274,\n",
              " 'rank': 275,\n",
              " 'due': 276,\n",
              " 'subordinate': 277,\n",
              " 'social': 278,\n",
              " 'standing': 279,\n",
              " 'however': 280,\n",
              " 'heroes': 281,\n",
              " 'not': 282,\n",
              " 'made': 283,\n",
              " 'according': 284,\n",
              " 'credentials': 285,\n",
              " 'they': 286,\n",
              " \"'re\": 287,\n",
              " 'through': 288,\n",
              " 'willingness': 289,\n",
              " 'greater': 290,\n",
              " 'others': 291,\n",
              " 'tries': 292,\n",
              " 'every': 293,\n",
              " 'turn': 294,\n",
              " 'prove': 295,\n",
              " 'mettle': 296,\n",
              " 'will': 297,\n",
              " 'passionately': 298,\n",
              " '....': 299,\n",
              " 'better': 300,\n",
              " 'am': 301,\n",
              " 'hollywood': 302,\n",
              " 'classics': 303,\n",
              " 'perfect': 304,\n",
              " '10': 305,\n",
              " 'expecting': 306,\n",
              " 'powerful': 307,\n",
              " 'filmmaking': 308,\n",
              " 'experience': 309,\n",
              " 'girlfight': 310,\n",
              " 'indie': 311,\n",
              " 'low': 312,\n",
              " 'budget': 313,\n",
              " 'no': 314,\n",
              " 'big': 315,\n",
              " 'name': 316,\n",
              " 'freshman': 317,\n",
              " 'director': 318,\n",
              " 'had': 319,\n",
              " 'heard': 320,\n",
              " 'placed': 321,\n",
              " 'contemporary': 322,\n",
              " 'ethnic': 323,\n",
              " 'working': 324,\n",
              " 'class': 325,\n",
              " 'brooklyn': 326,\n",
              " 'karyn': 327,\n",
              " 'kusama': 328,\n",
              " 'done': 329,\n",
              " 'extraordinary': 330,\n",
              " 'capturing': 331,\n",
              " 'day': 332,\n",
              " 'struggles': 333,\n",
              " 'urban': 334,\n",
              " 'latinos': 335,\n",
              " 'diana': 336,\n",
              " 'protagonist': 337,\n",
              " 'seething': 338,\n",
              " 'anger': 339,\n",
              " 'lashes': 340,\n",
              " 'high': 341,\n",
              " 'school': 342,\n",
              " 'peers': 343,\n",
              " 'getting': 344,\n",
              " 'trouble': 345,\n",
              " 'friends': 346,\n",
              " 'she': 347,\n",
              " 'raised': 348,\n",
              " 'single': 349,\n",
              " 'father': 350,\n",
              " 'appears': 351,\n",
              " 'brother': 352,\n",
              " 'applies': 353,\n",
              " 'strict': 354,\n",
              " 'sex': 355,\n",
              " 'based': 356,\n",
              " 'double': 357,\n",
              " 'standard': 358,\n",
              " 'children': 359,\n",
              " 'illustrated': 360,\n",
              " 'fact': 361,\n",
              " 'tiny': 362,\n",
              " 'taking': 363,\n",
              " 'boxing': 364,\n",
              " 'lessons': 365,\n",
              " 'gym': 366,\n",
              " 'denied': 367,\n",
              " 'similar': 368,\n",
              " 'pursuits': 369,\n",
              " 'errand': 370,\n",
              " 'meet': 371,\n",
              " 'captivated': 372,\n",
              " 'trade': 373,\n",
              " 'places': 374,\n",
              " 'gets': 375,\n",
              " 'money': 376,\n",
              " 'dad': 377,\n",
              " 'take': 378,\n",
              " 'actually': 379,\n",
              " 'feel': 380,\n",
              " 'grows': 381,\n",
              " 'learns': 382,\n",
              " 'herself': 383,\n",
              " 'meets': 384,\n",
              " 'guy': 385,\n",
              " 'addresses': 386,\n",
              " 'some': 387,\n",
              " 'serious': 388,\n",
              " 'issues': 389,\n",
              " 'head': 390,\n",
              " 'giggly': 391,\n",
              " \"'\": 392,\n",
              " 'everything': 393,\n",
              " 'go': 394,\n",
              " 'right': 395,\n",
              " 'resolution': 396,\n",
              " 'la': 397,\n",
              " 'bend': 398,\n",
              " 'beckham': 399,\n",
              " 'reality': 400,\n",
              " 'attendant': 401,\n",
              " 'personal': 402,\n",
              " 'pat': 403,\n",
              " 'resolutions': 404,\n",
              " 'satisfying': 405,\n",
              " 'acting': 406,\n",
              " 'superb': 407,\n",
              " 'mixed': 408,\n",
              " 'truth': 409,\n",
              " 'condition': 410,\n",
              " 'many': 411,\n",
              " 'africans': 412,\n",
              " 'south': 413,\n",
              " 'africa': 414,\n",
              " 'heart': 415,\n",
              " 'wrenching': 416,\n",
              " 'writer': 417,\n",
              " 'isolated': 418,\n",
              " 'boesman': 419,\n",
              " 'lena': 420,\n",
              " 'run': 421,\n",
              " 'homes': 422,\n",
              " 'we': 423,\n",
              " 'could': 424,\n",
              " 'share': 425,\n",
              " 'fully': 426,\n",
              " 'triumphs': 427,\n",
              " 'defeats': 428,\n",
              " 'conflicts': 429,\n",
              " 'shared': 430,\n",
              " 'grew': 431,\n",
              " 'together': 432,\n",
              " 'apart': 433,\n",
              " 'worth': 434,\n",
              " 'seeing': 435,\n",
              " 'put': 436,\n",
              " 'proper': 437,\n",
              " 'context': 438,\n",
              " 'sitting': 439,\n",
              " 'alone': 440,\n",
              " 'flat': 441,\n",
              " 'saturday': 442,\n",
              " 'night': 443,\n",
              " 'choice': 444,\n",
              " 'watching': 445,\n",
              " 'citizen': 446,\n",
              " 'eurovision': 447,\n",
              " 'song': 448,\n",
              " 'contest': 449,\n",
              " 'benefit': 450,\n",
              " 'americans': 451,\n",
              " 'reading': 452,\n",
              " 'explain': 453,\n",
              " 'annual': 454,\n",
              " 'event': 455,\n",
              " 'where': 456,\n",
              " 'musicians': 457,\n",
              " 'countries': 458,\n",
              " 'over': 459,\n",
              " 'europe': 460,\n",
              " 'asia': 461,\n",
              " 'minor': 462,\n",
              " 'end': 463,\n",
              " 'vote': 464,\n",
              " 'what': 465,\n",
              " 'even': 466,\n",
              " 'less': 467,\n",
              " 'exciting': 468,\n",
              " 'sounds': 469,\n",
              " 'may': 470,\n",
              " 'shock': 471,\n",
              " 'singing': 472,\n",
              " 'songwriting': 473,\n",
              " 'calibre': 474,\n",
              " 'lennon': 475,\n",
              " 'mccartney': 476,\n",
              " 'correct': 477,\n",
              " 'something': 478,\n",
              " 'first': 479,\n",
              " 'sentence': 480,\n",
              " 'review': 481,\n",
              " 'because': 482,\n",
              " 'word': 483,\n",
              " 'misleading': 484,\n",
              " 'music': 485,\n",
              " 'lover': 486,\n",
              " 'going': 487,\n",
              " 'watch': 488,\n",
              " 'under': 489,\n",
              " 'any': 490,\n",
              " 'circumstance': 491,\n",
              " 'sat': 492,\n",
              " 'down': 493,\n",
              " 'credits': 494,\n",
              " 'rolled': 495,\n",
              " 'mill': 496,\n",
              " 'serial': 497,\n",
              " 'killer': 498,\n",
              " 'whodunnit': 499,\n",
              " \"'d\": 500,\n",
              " 'calling': 501,\n",
              " 'obvious': 502,\n",
              " 'within': 503,\n",
              " 'point': 504,\n",
              " 'failures': 505,\n",
              " 'communism': 506,\n",
              " 'comrade': 507,\n",
              " 'soviet': 508,\n",
              " 'union': 509,\n",
              " 'killers': 510,\n",
              " 'exist': 511,\n",
              " 'decadent': 512,\n",
              " 'imperialist': 513,\n",
              " 'capitalist': 514,\n",
              " 'systems': 515,\n",
              " 'farcical': 516,\n",
              " 'attitude': 517,\n",
              " 'goes': 518,\n",
              " 'denial': 519,\n",
              " 'scene': 520,\n",
              " 'undercover': 521,\n",
              " 'cop': 522,\n",
              " 'sits': 523,\n",
              " 'freezing': 524,\n",
              " 'train': 525,\n",
              " 'station': 526,\n",
              " 'keeping': 527,\n",
              " 'eye': 528,\n",
              " 'potential': 529,\n",
              " 'suspects': 530,\n",
              " 'whilst': 531,\n",
              " 'wearing': 532,\n",
              " 'police': 533,\n",
              " 'jacket': 534,\n",
              " 'warm': 535,\n",
              " 'coat': 536,\n",
              " 'got': 537,\n",
              " 'course': 538,\n",
              " 'members': 539,\n",
              " 'communist': 540,\n",
              " 'party': 541,\n",
              " 'released': 542,\n",
              " 'without': 543,\n",
              " 'interrogation': 544,\n",
              " 'affect': 545,\n",
              " 'final': 546,\n",
              " 'death': 547,\n",
              " 'toll': 548,\n",
              " 'well': 549,\n",
              " 'shown': 550,\n",
              " 'system': 551,\n",
              " 'trial': 552,\n",
              " 'two': 553,\n",
              " 'thirds': 554,\n",
              " 'way': 555,\n",
              " 'find': 556,\n",
              " 'ourselves': 557,\n",
              " '1990': 558,\n",
              " 'its': 559,\n",
              " 'last': 560,\n",
              " 'legs': 561,\n",
              " 'investigation': 562,\n",
              " 'taken': 563,\n",
              " 'becomes': 564,\n",
              " 'uninteresting': 565,\n",
              " 'lack': 566,\n",
              " 'political': 567,\n",
              " 'subtext': 568,\n",
              " 'descends': 569,\n",
              " 'into': 570,\n",
              " 'average': 571,\n",
              " 'manhunt': 572,\n",
              " 'let': 573,\n",
              " 'off': 574,\n",
              " 'intelligent': 575,\n",
              " 'thriller': 576,\n",
              " 'cast': 577,\n",
              " 'donald': 578,\n",
              " 'sutherland': 579,\n",
              " 'paternal': 580,\n",
              " 'chief': 581,\n",
              " 'strangely': 582,\n",
              " 'few': 583,\n",
              " 'years': 584,\n",
              " 'ago': 585,\n",
              " 'read': 586,\n",
              " 'written': 587,\n",
              " 'famous': 588,\n",
              " 'colin': 589,\n",
              " 'wilson': 590,\n",
              " 'said': 591,\n",
              " 'along': 592,\n",
              " 'lines': 593,\n",
              " 'themselves': 594,\n",
              " 'get': 595,\n",
              " 'caught': 596,\n",
              " 'center': 597,\n",
              " 'attention': 598,\n",
              " 'media': 599,\n",
              " 'spotlight': 600,\n",
              " 'found': 601,\n",
              " 'myself': 602,\n",
              " 'chiefs': 603,\n",
              " 'denying': 604,\n",
              " 'after': 605,\n",
              " 'controlled': 606,\n",
              " 'anyone': 607,\n",
              " 'old': 608,\n",
              " 'listened': 609,\n",
              " 'radio': 610,\n",
              " 'moscow': 611,\n",
              " 'english': 612,\n",
              " 'translations': 613,\n",
              " 'know': 614,\n",
              " 'ussr': 615,\n",
              " 'reported': 616,\n",
              " 'news': 617,\n",
              " 'potato': 618,\n",
              " 'coal': 619,\n",
              " 'production': 620,\n",
              " 'thank': 621,\n",
              " 'letters': 622,\n",
              " 'afghanistan': 623,\n",
              " 'cuba': 624,\n",
              " 'etc': 625,\n",
              " 'assistance': 626,\n",
              " 'concept': 627,\n",
              " 'becoming': 628,\n",
              " 'illogical': 629,\n",
              " 'tree': 630,\n",
              " 'falls': 631,\n",
              " 'remote': 632,\n",
              " 'siberian': 633,\n",
              " 'forest': 634,\n",
              " 'sound': 635,\n",
              " 'around': 636,\n",
              " 'hear': 637,\n",
              " 'jim': 638,\n",
              " 'thompson': 639,\n",
              " 'adaptations': 640,\n",
              " 'known': 641,\n",
              " 'grifters': 642,\n",
              " 'dark': 643,\n",
              " 'hallmarks': 644,\n",
              " 'dangerous': 645,\n",
              " 'women': 646,\n",
              " 'confidence': 647,\n",
              " 'game': 648,\n",
              " 'characters': 649,\n",
              " 'either': 650,\n",
              " 'dim': 651,\n",
              " 'suspect': 652,\n",
              " 'them': 653,\n",
              " 'harmless': 654,\n",
              " 'jason': 655,\n",
              " 'patric': 656,\n",
              " 'former': 657,\n",
              " 'boxer': 658,\n",
              " 'disqualified': 659,\n",
              " 'sport': 660,\n",
              " 'incident': 661,\n",
              " 'ring': 662,\n",
              " 'james': 663,\n",
              " 'foley': 664,\n",
              " 'uses': 665,\n",
              " 'raging': 666,\n",
              " 'bull': 667,\n",
              " 'esquire': 668,\n",
              " 'sequences': 669,\n",
              " 'flesh': 670,\n",
              " 'back': 671,\n",
              " 'little': 672,\n",
              " 'rachel': 673,\n",
              " 'ward': 674,\n",
              " 'delivers': 675,\n",
              " 'bruce': 676,\n",
              " 'dern': 677,\n",
              " 'secret': 678,\n",
              " 'weapon': 679,\n",
              " 'sweet': 680,\n",
              " 'talking': 681,\n",
              " 'uncle': 682,\n",
              " 'bud': 683,\n",
              " 'subtly': 684,\n",
              " 'commands': 685,\n",
              " 'scenes': 686,\n",
              " 'comic': 687,\n",
              " 'relief': 688,\n",
              " 'prepared': 689,\n",
              " 'sucked': 690,\n",
              " 'void': 691,\n",
              " 'desperately': 692,\n",
              " 'difficult': 693,\n",
              " 'subject': 694,\n",
              " 'pull': 695,\n",
              " 'convincingly': 696,\n",
              " 'cinema': 697,\n",
              " 'encompassing': 698,\n",
              " 'passion': 699,\n",
              " 'involved': 700,\n",
              " 'generally': 701,\n",
              " 'ends': 702,\n",
              " 'pale': 703,\n",
              " 'imitation': 704,\n",
              " 'worse': 705,\n",
              " 'slightly': 706,\n",
              " 'ridiculous': 707,\n",
              " 'lifshitz': 708,\n",
              " 'manages': 709,\n",
              " 'avoid': 710,\n",
              " 'pitfalls': 711,\n",
              " 'sexy': 712,\n",
              " 'thoroughly': 713,\n",
              " 'engrossing': 714,\n",
              " 'tale': 715,\n",
              " 'disaster': 716,\n",
              " 'possible': 717,\n",
              " 'redemption': 718,\n",
              " 'while': 719,\n",
              " 'tangentially': 720,\n",
              " 'touching': 721,\n",
              " 'deeper': 722,\n",
              " 'themes': 723,\n",
              " 'human': 724,\n",
              " 'existence': 725,\n",
              " 'core': 726,\n",
              " 'mathieu': 727,\n",
              " '18': 728,\n",
              " 'solitary': 729,\n",
              " 'introverted': 730,\n",
              " 'boy': 731,\n",
              " 'cédric': 732,\n",
              " 'outgoing': 733,\n",
              " 'lonely': 734,\n",
              " 'holiday': 735,\n",
              " 'family': 736,\n",
              " 'summer': 737,\n",
              " 'warms': 738,\n",
              " 'fall': 739,\n",
              " 'holidays': 740,\n",
              " 'decide': 741,\n",
              " 'live': 742,\n",
              " 'later': 743,\n",
              " 'relationship': 744,\n",
              " 'catastrophe': 745,\n",
              " 'cheats': 746,\n",
              " 'distraught': 747,\n",
              " 'survives': 748,\n",
              " 'order': 749,\n",
              " 'perspective': 750,\n",
              " 'returns': 751,\n",
              " 'seaside': 752,\n",
              " 'town': 753,\n",
              " 'met': 754,\n",
              " 'cloaked': 755,\n",
              " 'chill': 756,\n",
              " 'winter': 757,\n",
              " 'impact': 758,\n",
              " 'much': 759,\n",
              " 'implied': 760,\n",
              " 'happens': 761,\n",
              " 'non': 762,\n",
              " 'intricate': 763,\n",
              " 'narrative': 764,\n",
              " 'essential': 765,\n",
              " 'feeling': 766,\n",
              " 'passions': 767,\n",
              " 'experienced': 768,\n",
              " 'use': 769,\n",
              " 'counterpoint': 770,\n",
              " 'temporal': 771,\n",
              " 'fortunately': 772,\n",
              " 'used': 773,\n",
              " 'post': 774,\n",
              " 'suicide': 775,\n",
              " 'psychiatric': 776,\n",
              " 'hospital': 777,\n",
              " 'colour': 778,\n",
              " 'coded': 779,\n",
              " 'yellows': 780,\n",
              " 'oranges': 781,\n",
              " 'frighteningly': 782,\n",
              " 'blue': 783,\n",
              " 'warming': 784,\n",
              " 'browns': 785,\n",
              " 'blues': 786,\n",
              " 'both': 787,\n",
              " 'main': 788,\n",
              " 'excellent': 789,\n",
              " 'performances': 790,\n",
              " 'delight': 791,\n",
              " 'stéphane': 792,\n",
              " 'rideau': 793,\n",
              " 'full': 794,\n",
              " 'capacity': 795,\n",
              " \"'m\": 796,\n",
              " 'him': 797,\n",
              " 'stretched': 798,\n",
              " 'gael': 799,\n",
              " 'limp': 800,\n",
              " 'dramas': 801,\n",
              " 'elkaim': 802,\n",
              " 'singled': 803,\n",
              " 'special': 804,\n",
              " 'mention': 805,\n",
              " 'loneliness': 806,\n",
              " 'incredulous': 807,\n",
              " 'crumbling': 808,\n",
              " 'behind': 809,\n",
              " 'wall': 810,\n",
              " 'beautifully': 811,\n",
              " 'crafted': 812,\n",
              " 'gestures': 813,\n",
              " 'across': 814,\n",
              " 'dialogue': 815,\n",
              " 'touched': 816,\n",
              " 'upon': 817,\n",
              " 'french': 818,\n",
              " 'our': 819,\n",
              " 'difficulty': 820,\n",
              " 'really': 821,\n",
              " 'understanding': 822,\n",
              " 'communicating': 823,\n",
              " 'shifting': 824,\n",
              " 'sands': 825,\n",
              " 'meaning': 826,\n",
              " '\\x85 ': 827,\n",
              " 'title': 828,\n",
              " 'presque': 829,\n",
              " 'rien': 830,\n",
              " 'nothing': 831,\n",
              " 'points': 832,\n",
              " 'these': 833,\n",
              " 'indeed': 834,\n",
              " 'key': 835,\n",
              " 'trying': 836,\n",
              " 'understand': 837,\n",
              " 'why': 838,\n",
              " 'attempted': 839,\n",
              " 'kill': 840,\n",
              " 'himself': 841,\n",
              " 'psychiatrist': 842,\n",
              " 'asks': 843,\n",
              " 'cheated': 844,\n",
              " 'une': 845,\n",
              " 'fois': 846,\n",
              " 'yes': 847,\n",
              " 'loves': 848,\n",
              " '\\x96': 849,\n",
              " 'brought': 850,\n",
              " 'during': 851,\n",
              " 'attempt': 852,\n",
              " 'none': 853,\n",
              " 'contact': 854,\n",
              " 'leaves': 855,\n",
              " 'lost': 856,\n",
              " 'forever': 857,\n",
              " 'seemed': 858,\n",
              " 'meaningless': 859,\n",
              " 'affair': 860,\n",
              " 'darker': 861,\n",
              " 'unfortunate': 862,\n",
              " 'pierre': 863,\n",
              " 'et': 864,\n",
              " 'gilles': 865,\n",
              " 'poster': 866,\n",
              " 'suggest': 867,\n",
              " 'hope': 868,\n",
              " 'slow': 869,\n",
              " 'painful': 870,\n",
              " 'attempts': 871,\n",
              " 'touch': 872,\n",
              " 'cat': 873,\n",
              " 'adopts': 874,\n",
              " 'bar': 875,\n",
              " 'finally': 876,\n",
              " 'next': 877,\n",
              " 'here': 878,\n",
              " 'teenage': 879,\n",
              " 'perhaps': 880,\n",
              " 'beginning': 881,\n",
              " 'certainly': 882,\n",
              " 'living': 883,\n",
              " '\\x85': 884,\n",
              " 'such': 885,\n",
              " 'shame': 886,\n",
              " 'avoided': 887,\n",
              " 'people': 888,\n",
              " 'hate': 889,\n",
              " 'football': 890,\n",
              " 'cheesy': 891,\n",
              " 'sports': 892,\n",
              " 'flick': 893,\n",
              " 'line': 894,\n",
              " 'soppy': 895,\n",
              " 'jokes': 896,\n",
              " 'laugh': 897,\n",
              " 'loud': 898,\n",
              " 'funny': 899,\n",
              " 'acted': 900,\n",
              " 'parminder': 901,\n",
              " 'nagra': 902,\n",
              " 'keira': 903,\n",
              " 'knightley': 904,\n",
              " 'brilliant': 905,\n",
              " 'teenagers': 906,\n",
              " 'jess': 907,\n",
              " 'jules': 908,\n",
              " 'putting': 909,\n",
              " 'pitch': 910,\n",
              " 'anupam': 911,\n",
              " 'kher': 912,\n",
              " 'wonderful': 913,\n",
              " 'worried': 914,\n",
              " 'jonathan': 915,\n",
              " 'rhys': 916,\n",
              " 'meyers': 917,\n",
              " 'amazingly': 918,\n",
              " 'evil': 919,\n",
              " 'ride': 920,\n",
              " 'devil': 921,\n",
              " 'nice': 922,\n",
              " 'making': 923,\n",
              " 'gorgeous': 924,\n",
              " 'irish': 925,\n",
              " 'accent': 926,\n",
              " 'anything': 927,\n",
              " 'smile': 928,\n",
              " 'wonder': 929,\n",
              " 'watched': 930,\n",
              " 'admittedly': 931,\n",
              " 'viewed': 932,\n",
              " 'knew': 933,\n",
              " 'beatles': 934,\n",
              " 'names': 935,\n",
              " 'ton': 936,\n",
              " 'fans': 937,\n",
              " 'albums': 938,\n",
              " 'claim': 939,\n",
              " 'broke': 940,\n",
              " 'john': 941,\n",
              " 'married': 942,\n",
              " 'yoko': 943,\n",
              " 'murdered': 944,\n",
              " 'vh1': 945,\n",
              " 'favorite': 946,\n",
              " 'mtv': 947,\n",
              " 'reason': 948,\n",
              " 'decided': 949,\n",
              " 'surprisingly': 950,\n",
              " 'enjoyed': 951,\n",
              " 'handled': 952,\n",
              " 'occasion': 953,\n",
              " 'slight': 954,\n",
              " 'mess': 955,\n",
              " 'important': 956,\n",
              " 'paul': 957,\n",
              " 'pretty': 958,\n",
              " 'outside': 959,\n",
              " 'explore': 960,\n",
              " 'possibilities': 961,\n",
              " 'keep': 962,\n",
              " 'jared': 963,\n",
              " 'harris': 964,\n",
              " 'quinn': 965,\n",
              " 'give': 966,\n",
              " 'overall': 967,\n",
              " 'ending': 968,\n",
              " 'smart': 969,\n",
              " 'how': 970,\n",
              " 'excited': 971,\n",
              " 'snl': 972,\n",
              " 'performace': 973,\n",
              " 'slaps': 974,\n",
              " 'makes': 975,\n",
              " 'realize': 976,\n",
              " 'note': 977,\n",
              " 'moment': 978,\n",
              " 'probably': 979,\n",
              " 'rooftop': 980,\n",
              " 'recommend': 981,\n",
              " 'settling': 982,\n",
              " 'your': 983,\n",
              " 'curiosity': 984,\n",
              " 'happened': 985,\n",
              " '6': 986,\n",
              " 'break': 987,\n",
              " 'showed': 988,\n",
              " 'doorstep': 989,\n",
              " 'viewing': 990,\n",
              " 'breakup': 991,\n",
              " 'walt': 992,\n",
              " 'disney': 993,\n",
              " 'ralph': 994,\n",
              " 'bakshi': 995,\n",
              " 'response': 996,\n",
              " 'coonskin': 997,\n",
              " 'afro': 998,\n",
              " 'video': 999,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V84fsbBMTl8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_sentence(path, vocab2index, N=400, padding_start=True):\n",
        "    x = spacy_tok(path.read_text())\n",
        "    enc = np.zeros(N, dtype=np.int32)\n",
        "    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n",
        "    l = min(N, len(enc1))\n",
        "    if padding_start:\n",
        "        enc[:l] = enc1[:l]\n",
        "    else:\n",
        "        enc[N-l:] = enc1[:l]\n",
        "    return enc, l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rET5Unbehb7N",
        "colab_type": "code",
        "outputId": "acc42ec4-91a0-474d-c0ef-ffca9d93317a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "path = PATH/'train/pos/10544_8.txt'\n",
        "encode_sentence(path, vocab2index, N = 400, padding_start= False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,   549,    28,   226, 11593,\n",
              "          226,    66,  2680,    80,    28, 13368,    34,   479,    92,\n",
              "           28,    41,    71,     3,     6,  1058,  1168,    37,  6113,\n",
              "         5278,    96,    94,  1439,    82,   140,   133,   681,    76,\n",
              "         1368,    10,   286,   319,   196,    71,  3542,    28,    14,\n",
              "         3649,     3,   119,    37,    14,  1263,    10,   125,    28,\n",
              "          465,   283,    40,   125,   804,   136,    20,     6,  5880,\n",
              "          120,    28,   211,  7051,    37,    14,  2487,   410,    96,\n",
              "          649,   319,   100,  1893,   138,  9445,     5,    14,  7762,\n",
              "           10,    83,  1600,    92,    28,   226, 11522,   226,    66,\n",
              "         2683,    80,    28,    41,    20,    76,   559,     2,    28,\n",
              "          106,    40,    41,    57,   125,   169,    39,   226, 11593,\n",
              "          226,   106,   878,    22,     6,   649,    69, 19510,   138,\n",
              "         9445,   219,    10,    42,   226,   831,   226,    13,   478,\n",
              "          168,  1168,    37,   375, 13368,  1529,   671,   100,    83,\n",
              "          392, 11593,  1471,   392,    28,  8826,     6,   649,    45,\n",
              "          219,     5,    14,   168,   165,  2370,   113,   314,    18,\n",
              "           45,    46,  2030,   113,     6,   649,   138,  2030,   113,\n",
              "         9445,     5,   114,   309,  3874,    10,   106,  1464,     3,\n",
              "           14,   576,  1153,    84,  1154,    66,   466,   387,     3,\n",
              "            6, 10334, 23542,    37, 14084,  5734,   858,   138,    96,\n",
              "           80,    28,   226,   831,   226,    13,    14,  3086,    37,\n",
              "         2021,    88,    96,   109,  1040,   272,   143,  1735,    14,\n",
              "         1798,  3262,    76,   819,  1799,    37,   183,    76,     6,\n",
              "        23543,  1379,   423,   287,   883,    10,    45,   219,     1,\n",
              "         4907,  1543,   113,    14,   211,   155,   570,    14,   125,\n",
              "           17,  2046,     3,   189,    10,  1506,   119,    37,    14,\n",
              "        15389,  1010, 11319,    28,    96,    34,    20,   126,   537,\n",
              "         1058,  1078,     3,    18,    37,   126,   128,    57,  1484,\n",
              "           46,   194,    96,    10,   719,   226, 11593,   226,    13,\n",
              "           14,  7073,   309,    37,   226, 11522,   226,  1831,    28,\n",
              "          226,   831,   226,    13,  3123,     6,  6951,   106,   213,\n",
              "            6,  1502,    18,   183,  2608,    10,    42,    11,    92,\n",
              "         2548,    45,   219,    96,    14,   969,   155,  3178,   759,\n",
              "           46,   194,   196,    14,  3885,   313,    10,     3,   538,\n",
              "           96,     6,    92,  3612,  1483,    28,   106,   559,  6147,\n",
              "          155,  3178,    14,  2076,    37,     1,   490,  4816,    10,\n",
              "           23,    34,   831,    46,   100,   143,   591,    76,    11,\n",
              "           92,   482,   393,    13,    14,   905,  1458,    37,    14,\n",
              "         1175,   165,   309,    96,    94,   319,     5,  1368,  1284,\n",
              "          226, 11593,   226,    10], dtype=int32), 359)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcsukIekllvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImdbDataset(Dataset):\n",
        "    def __init__(self, PATH, train = \"train\", N = 400, padding_start = True):\n",
        "       self.path_to_images = PATH/train\n",
        "       self.pos_files = list((self.path_to_images/\"pos\").iterdir())\n",
        "       self.neg_files = list((self.path_to_images/\"neg\").iterdir())\n",
        "       self.files = self.pos_files + self.neg_files\n",
        "       self.y = np.concatenate((np.ones(len(self.pos_files), dtype= int),\n",
        "                             np.zeros(len(self.neg_files), dtype = int)), axis = 0)\n",
        "       self.X = [encode_sentence(path, vocab2index, N, padding_start) for path in self.files]\n",
        "    def __len__(self):\n",
        "       return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "       x, s = self.X[idx]\n",
        "       return x, s, self.y[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90CcnRqiyMce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds_v0 = ImdbDataset(PATH, padding_start= False)\n",
        "valid_ds_v0 = ImdbDataset(PATH, \"test\", padding_start= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA1dqe5dy0kI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1000\n",
        "train_dl_v0 = DataLoader(train_ds_v0, batch_size= batch_size, shuffle= True)\n",
        "valid_dl_v0 = DataLoader(valid_ds_v0, batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IMhYRzn1myM",
        "colab_type": "code",
        "outputId": "8740887a-67d9-4f57-ce9e-866f67b587d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "train_ds_v0[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  44,  45,  46,\n",
              "         47,  14,  48,  49,   5,  50,  28,  11,  18,  28,  51,  52,   6,\n",
              "         53,   3,  14,  54,  55,  56,  57,  58,  59,  60,  61,  37,  62,\n",
              "         28,  37,   6,  63,  15,  64,  65,  66,  55,  28,  67,  68,  69,\n",
              "         70,  28,  39,  71,  72,  73,  28,  74,  14,  75,  76,  77,  78,\n",
              "         79,  80,  13,  39,  81,  39,  82,  39,  83,  82,  84,  85,   1,\n",
              "         34,  86,  14,  87,  88,  28,  86,  14,  89,  90,  84,  91,  92,\n",
              "         28,  86,  14,  93,  28,  94,  95,  28,  96,  97,  57,  98,  99,\n",
              "         40, 100,  14, 101,  10,  40, 102,  57,  98, 103, 104, 105,  28,\n",
              "        106,  40, 107,  20,   6, 108, 109,  14, 110, 111, 112, 113, 114,\n",
              "        115, 106,   1, 116,  28, 117, 118, 119,  28,  37, 120,  96, 121,\n",
              "         40,  20, 122, 123, 124, 125,  96, 126, 127, 128,  57, 129,  96,\n",
              "        130,  66,  44,  80,  13,  57, 131, 132, 133,  40, 134, 100,   1,\n",
              "         10,  94, 135,  23, 136,  46, 137, 138,  11,  10], dtype=int32),\n",
              " 170,\n",
              " 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GL5VzKZOLbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset with padding at the end\n",
        "train_ds = ImdbDataset(PATH)\n",
        "valid_ds = ImdbDataset(PATH, \"test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNQ8f-YfgAYY",
        "colab_type": "text"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTi61pT1ddog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMModel(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "    super(LSTMModel, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx= 0)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first = True)\n",
        "    self.linear = nn.Linear(hidden_dim, 1)\n",
        "  \n",
        "  def forward(self, x, s):\n",
        "    s, sort_index = torch.sort(s, 0, descending= True)\n",
        "    s = s.numpy().tolist()\n",
        "    x = x[sort_index]\n",
        "    x = self.embeddings(x)\n",
        "    x = self.dropout(x)\n",
        "    x_pack = pack_padded_sequence(x, s, batch_first= True)\n",
        "    out_pack, (ht, ct) = self.lstm(x_pack)\n",
        "    out = self.linear(ht[-1])\n",
        "    return torch.zeros_like(out).scatter_(0, sort_index.unsqueeze(1).cuda(), out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QIm3jIjoene",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epochs(model, epochs = 10, lr = 0.001):\n",
        "  parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "  optimizer = torch.optim.Adam(parameters, lr = lr)\n",
        "  for i in range(epochs):\n",
        "    model.train()\n",
        "    sum_loss = 0.0\n",
        "    total = 0\n",
        "    for x, s, y in train_dl:\n",
        "      x = x.long().cuda()\n",
        "      y = y.float().cuda()\n",
        "      y_pred = model(x, s)\n",
        "      optimizer.zero_grad()\n",
        "      loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      sum_loss += loss.item() * y.shape[0]\n",
        "      total += y.shape[0]\n",
        "    val_loss, val_acc = val_metrics(model, val_dl)\n",
        "    if i %5 == 1:\n",
        "      print(\"train loss %.3f val loss %.3f and val accuacy %.3f\" % (sum_loss/total, val_loss, val_acc))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WpL-IhorX8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_metrics(model, val_dl):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  sum_loss = 0.0\n",
        "  for x, s, y in val_dl:\n",
        "    x = x.long().cuda()\n",
        "    y = y.float().unsqueeze(1).cuda()\n",
        "    y_hat = model(x, s)\n",
        "    loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "    y_pred = y_hat > 0\n",
        "    correct += (y_pred.float() == y).float().sum()\n",
        "    total += y.shape[0]\n",
        "    sum_loss += loss.item() * y.shape[0]\n",
        "  return sum_loss/total, correct/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqaJwgOusok3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1000\n",
        "train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "val_dl = DataLoader(valid_ds, batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAMpFHDhtHaz",
        "colab_type": "code",
        "outputId": "892e7409-7619-45e0-8f58-ff6ecc22c5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(words)\n",
        "print(vocab_size)\n",
        "model = LSTMModel(vocab_size, 50, 100).cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1XYHfh5ZEZ1",
        "colab_type": "code",
        "outputId": "85dae197-f30d-48a7-dded-84f8a50fdcc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_epochs(model, epochs = 20, lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loss 0.090 val loss 0.413 and val accuacy 0.869\n",
            "train loss 0.058 val loss 0.546 and val accuacy 0.860\n",
            "train loss 0.044 val loss 0.569 and val accuacy 0.855\n",
            "train loss 0.030 val loss 0.644 and val accuacy 0.858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqwrxlJmCE12",
        "colab_type": "text"
      },
      "source": [
        "GRU with dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPDmKXgZiHeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRUModel(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "    super(GRUModel, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx = 0)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first = True)\n",
        "    self.linear = nn.Linear(hidden_dim, 1)\n",
        "  \n",
        "  def forward(self, x, s):\n",
        "    s, sort_index = torch.sort(s, 0, descending = True)\n",
        "    s = s.numpy().tolist()\n",
        "    x = x[sort_index]\n",
        "    x = self.embeddings(x)\n",
        "    x = self.dropout(x)\n",
        "    x_pack = pack_padded_sequence(x, list(s), batch_first = True)\n",
        "    out_pack, ht = self.gru(x_pack)\n",
        "    out = self.linear(ht[-1])\n",
        "    return torch.zeros_like(out).scatter_(0, sort_index.unsqueeze(1).cuda(), out) #returns a tensor filled with the scaler value 0 and with the same size \n",
        "    #as the input. torch.zeros_like(input, out) = torch.zeros(input.size(), out)\n",
        "    #.scatter_() send the elements of x to the following indices in torch.zeros according row wise element\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNRXIS8IHlHa",
        "colab_type": "code",
        "outputId": "42b45fa6-1e86-4a24-e518-8b719c3f7934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(words)\n",
        "print(vocab_size)\n",
        "model2 = GRUModel(vocab_size, 50, 100).cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svXwsuNdL12s",
        "colab_type": "code",
        "outputId": "b8c9152f-4bf2-4be3-b422-aa46d68d1766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_epochs(model2, epochs = 20, lr = 0.009)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loss 0.053 val loss 0.461 and val accuacy 0.878\n",
            "train loss 0.029 val loss 0.608 and val accuacy 0.873\n",
            "train loss 0.021 val loss 0.680 and val accuacy 0.873\n",
            "train loss 0.020 val loss 0.795 and val accuacy 0.867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1ME0ZyTRH1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}